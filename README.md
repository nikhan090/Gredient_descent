**Gradient Descent Implementation**

This repository contains a simple Python implementation of **Gradient Descent** for linear regression, applied to a small dataset of house sizes and prices.  

 📌 Features
- Normalizes input features for better convergence.
- Implements batch gradient descent from scratch using NumPy.
- Tracks cost function values over iterations.
- Displays data visualization using Matplotlib.
- Stores iteration details (Theta values & Cost) in a Pandas DataFrame.

📂 **Files**
- **Gredient_descent.py** — Main script implementing gradient descent for a simple dataset.

**📊 Dataset**
The dataset is hardcoded for demonstration purposes:

| Size (sq ft) | Price ($1000s) |
|--------------|----------------|
| 500          | 50             |
| 1000         | 100            |
| 1500         | 150            |
| 2000         | 200            |

 ⚙️ **Requirements**
Make sure you have the following Python libraries installed:

pip install numpy pandas matplotlib 
📈 **parameter
ter**
Normalized feature plot.

Iteration log showing:

Theta 0 (intercept)

Theta 1 (slope)

Cost function value

Final trainparameter
🧠 Learning Objective
This project is designed to help beginners understand:

The mathematics behind gradient descent.

How normalization improves training.

How cost decreases over iterations.ter
